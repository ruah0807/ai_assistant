{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 패키지의 버전 정보 확인\n",
    "%pip show openai | grep Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import json \n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "print(openai.__version__)\n",
    "\n",
    "def show_json(obj):\n",
    "    #obj의 모델을 Json 형태로 변환 후 출력\n",
    "    display(json.loads(obj.model_dump_json()))\n",
    "\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "# Open ai API를 사용하기 위한 클라이언트 객체생성\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"상표 식별력 판단 AI(GPT-4o)\",\n",
    "    instructions=\"\"\"\n",
    "    1. Role\n",
    "    상표 식별력 판단 AI 서비스는 업로드한 파일들을 Retrieval 하고, 상표의 이미지 또는 텍스트를 분석하여, 해당 상표의 식별력을 평가하고 등록 가능성을 판단하는 역할을 수행합니다.\n",
    "\"\"\",\n",
    "model='gpt-4o',\n",
    "\n",
    ")\n",
    "# 생성된 챗봇의 정보를 json 형태로 출력 \n",
    "show_json(assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSISTANT 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_delete = client.beta.assistants.delete(\n",
    "    assistant_id = 'asst_x80ooPyJACW7qsswAChpQyMG'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 어시스턴트 ID 확인\n",
    "assistant_list = client.beta.assistants.list()\n",
    "\n",
    "for assistant in assistant_list:\n",
    "    print(f\"Assistant Name: {assistant.name}, Assistant ID: {assistant.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant id를 별도의 변수에 담음\n",
    "ASSISTANT_ID = 'asst_GDlNLfM4j2LCpTYFgULSR1V6'\n",
    "\n",
    "print(f\"[새로 생성한 ASSISTANT_ID]\\n{ASSISTANT_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistant 삭제\n",
    "client.beta.assistants.delete(assistant_id='asst_GDlNLfM4j2LCpTYFgULSR1V6')\n",
    "# print(f\"어시스턴트 {ASSISTANT_ID}가 삭제되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 업데이트 및 Code_interpreter\n",
    " assistant가 자체적으로 구동이 가능한 코드를 구현하고 query를 만들어 검색\n",
    "- 데이터가 많을 경우 토큰을 효율적으로 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update assistant\n",
    "assistant = client.beta.assistants.update(\n",
    "    ASSISTANT_ID,\n",
    "    tools=[{'type':'code_interpreter'}], \n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files(files):\n",
    "    uploaded_files = []\n",
    "    for filepath in files:\n",
    "        file = client.beta.create(\n",
    "            file = open(\n",
    "                filepath,\n",
    "                'rb'\n",
    "            ),\n",
    "            purpose='assistants'\n",
    "        )\n",
    "        uploaded_files.append(file.id)\n",
    "        print(f'[업로드한 파일 ID]\\n{file.id}')\n",
    "    return uploaded_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#업로드할 파일들의 경로를 지정\n",
    "files_to_uploaded = [\n",
    "    '_docs/example/[의견서예시][의견서미제출-거절]선행상표조사_MindShare.pdf',\n",
    "    '_docs/example/[의견서예시][의견서제출-거절]crople선행상표조사보고서(제출).pdf',\n",
    "    '_docs/example/[의견서예시]몸선필라테스&발레핏.pdf',\n",
    "    '_docs/example/상표검색 프로세스.pdf',\n",
    "    '_docs/example/상표심사기준202405.pdf',\n",
    "    '_docs/example/선행상표조사결과(샘플)_화음이 만든 샘플임_240822.pdf',\n",
    "    '_docs/example/상표유사여부보고서(별책).pdf',\n",
    "\n",
    "]\n",
    "\n",
    "file_streams = [open(path, 'rb') for path in files_to_uploaded]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 백터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = client.beta.vector_stores.create(\n",
    "#     name = '상표 식별 documents',\n",
    "# )\n",
    "\n",
    "vector_store = client.beta.vector_stores.update(\n",
    "    vector_store_id= 'vs_lnyjqbRPhkqR5RkQ3Y3pdiN1'\n",
    ")\n",
    "show_json(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.beta.vector_stores.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.files.delete(\n",
    "    file_id=\n",
    "        'file-hpjBTNyZRMpQG4lxlqGLaa2c'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 업로드된 파일 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in client.files.list():\n",
    "    print(f'[파일 ID] {file.id} [파일명]{file.filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 파일을 업로드 하고 vector store에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 업로드 및 백터 스토어에 추가\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files = file_streams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 백터스토어 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore Name: 의견서 작성 예시, Vectorstore ID: vs_I1f6CEXf49Ul7Ko6iOx5oeQ8\n",
      "Vectorstore Name: Similarity Code Batch Ver., Vectorstore ID: vs_0dJoKkouQ6Qa7HbczRnwC1VG\n",
      "Vectorstore Name: Similarity Code, Vectorstore ID: vs_m1b79x1RYgGhA6f8qaUIHzUU\n",
      "Vectorstore Name: Vienna Code, Vectorstore ID: vs_QtSniSyyBiMQ8P8AJYONaBJq\n",
      "Vectorstore Name: 상표 식별 documents, Vectorstore ID: vs_rLXYrSoCNE7aNpLI6cBGPseN\n"
     ]
    }
   ],
   "source": [
    "## 벡터스토어 리스트 검색 ###\n",
    "\n",
    "vector_store_list = client.beta.vector_stores.list()\n",
    "\n",
    "for vectorstore in vector_store_list:\n",
    "    print(f\"Vectorstore Name: {vectorstore.name}, Vectorstore ID: {vectorstore.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"edgar/aapl-10k.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    " \n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"How many shares of AAPL were outstanding at the end of of October 2023?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    " \n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 청크 검사 \n",
    "파일 검색 결과의 품질을 개선하기 위한 첫 번째 단계는 어시스턴트의 현재 동작을 검사하는 것입니다. \n",
    "대부분의 경우, 이는 성능이 좋지 않은 어시스턴트의 응답을 조사하는 것을 포함합니다. \n",
    "REST API를 사용하여 과거 실행 단계에 대한 세부 정보를 얻을 수 있으며 , \n",
    "특히 include쿼리 매개변수를 사용하여 결과를 생성하는 데 사용되는 파일 청크를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "run_step = client.beta.threads.runs.steps.retrieve(\n",
    "    thread_id=\"thread_abc123\",\n",
    "    run_id=\"run_abc123\",\n",
    "    step_id=\"step_abc123\",\n",
    "    include=[\"step_details.tool_calls[*].file_search.results[*].content\"]\n",
    ")\n",
    "\n",
    "print(run_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## vectorstore 삭제 ###\n",
    "vector_store = client.beta.vector_stores.delete(\n",
    "    vector_store_id='vs_ZOgnvSj623UBSYn3sdcRU3c0'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 새 백터 스토어를 사용하도록 어시스턴트 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드된 파일 참조 및 검색 요청\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=ASSISTANT_ID,\n",
    "    tool_resources={'file_search': {'vector_store_ids': [vector_store.id]}},\n",
    "    temperature=0\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 스레드 만들기\n",
    "스레드에 메시지 첨부파일로 파일을 첨부 가능\n",
    "vector_store 스레드와 연관된 다른 파일이 생성되거나, 스레드에 이미 벡터 스토어가 첨부 되어있는 경우 새 파일을 기존 스레드 벡터 스토어에 첨부\n",
    "\n",
    "\n",
    "\t1.\t파일 업로드: message_file 객체는 업로드된 이미지의 파일 ID를 가지고 있으며, 이 파일 ID를 스레드에서 사용하여 이미지 파일을 참조합니다.\n",
    "\t2.\t스레드 생성: thread 객체는 대화의 흐름을 관리하는 스레드이며, 여기에 사용자가 보낸 메시지(텍스트와 이미지)가 포함됩니다.\n",
    "\t3.\t어시스턴트 실행: client.beta.threads.runs.create()를 사용하여 스레드 내에서 어시스턴트를 실행시킵니다. 이때 어시스턴트의 ID가 필요하며, 해당 어시스턴트가 이미지를 분석할 수 있는지 확인해야 합니다.\n",
    "\t4.\t결과 확인: client.beta.threads.messages.list()로 스레드의 대화 내용을 확인하여 어시스턴트가 이미지에 대해 어떤 응답을 했는지 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "show_json(thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id= thread.id,\n",
    "    role='user',\n",
    "    content='식별력이 뭐야?'\n",
    ")\n",
    "show_json(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id, # 생성한스레드(카톡방)\n",
    "    assistant_id=ASSISTANT_ID # 적용할 AssistantID\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run을 생성하는 것은 비동기 작업이다.\n",
    "이는 Run의 메타데이터와 함께 즉시 반환되며, status 는 queued(대기중)으로 표기된다.\n",
    "status 는 Assistant가 작업을 수행함에 따라(도구 사용 및 메시지 추가와 같은) 업데이트될 것임.\n",
    "\n",
    "### status 목록\n",
    "- queued : 아직 실행이 되지 않고 대기중인 상태\n",
    "- in_progress: 처리중\n",
    "- requires_action : 사용자 입력 대기중\n",
    "- cancelling : 작업 취소중\n",
    "- cancelled : 취소 완료\n",
    "- failed: 오류(실패)\n",
    "- completed: 작업완료\n",
    "- expired: 작업 만료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def wait_on_run(run, thread):\n",
    "    # 주어진 실행 (run)이 완료 될때까지 대기\n",
    "    # status 가 'queued' 또는 'inprogress'인 경우에는 계속 polling 하며 대기\n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        # run.status를 업데이트 합니다.\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id = thread.id,\n",
    "            run_id= run.id\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 객체를 대기 상태로 설정하고, 해당 스레드에서 실행을 완료할 때가지 기다림\n",
    "run = wait_on_run(run, thread)\n",
    "\n",
    "# status가 'complete'인 경우에는 결과를 출력합니다.\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message(메세지)\n",
    "\n",
    "run이 완료되었다면, Assistant에 의해 처리된 결과를 보기 위해 Thread에서 messages를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread.id 를 사용하여 메시지 목록을 가져옴\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "\n",
    "#결과 출력\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 받은 답변을 기억하고 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id= thread.id,\n",
    "    role='user',\n",
    "    content='더 간단하게 말해줄래?'\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id= ASSISTANT_ID\n",
    ")\n",
    "\n",
    "# 답변 완료될때까지 대기\n",
    "wait_on_run(run, thread)\n",
    "\n",
    "# 마지막 사용자 메시지 이후 추가된 모든 메시지 검색\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, \n",
    "    order='asc', #오름차순으로 출력\n",
    "    after=message.id  # 이전 메세지를 제외하고 출력\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아미지 업로드와 함께 물어보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "    file = open('brand_img/여기의성.png','rb'),\n",
    "    purpose='vision'\n",
    ")\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id= thread.id,\n",
    "    role='user',\n",
    "    content=[\n",
    "        {\n",
    "            'type': 'text',\n",
    "            'text': '이 상표의 의견서를 제시해주세요'\n",
    "        },\n",
    "        {\n",
    "            'type': 'image_file',\n",
    "            'image_file': {'file_id': file.id}\n",
    "        }\n",
    "    ],\n",
    "    \n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id= ASSISTANT_ID,\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "# 답변 완료될때까지 대기\n",
    "wait_on_run(run, thread)\n",
    "\n",
    "# 마지막 사용자 메시지 이후 추가된 모든 메시지 검색\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, \n",
    "    # order='asc', #오름차순으로 출력\n",
    "    # after=message.id  # 이전 메세지를 제외하고 출력\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    #사용자 입력 메시지를 스레드에 추가\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id= thread.id,\n",
    "        role = \"user\",\n",
    "        content = user_message\n",
    "    )\n",
    "\n",
    "    #스레드에 메시지가 입력되었다면 실행 준비\n",
    "    run= client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    return run\n",
    "\n",
    "def wait_on_run(run,thread):\n",
    "    # run이 완료될대까지 기다림 : polling 하며 대기 (polling: 서버와 응답을 주고받음)\n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "def get_response(thread):\n",
    "    # 스레드에서 메세지 목록가져오기\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id, order='asc')\n",
    "\n",
    "\n",
    "# 새로운 스레드 생성 및 메시지 제출 함수\n",
    "def create_thread_and_run(user_input):\n",
    "    # 사용자 입력을 받아 새로운 스래드를 생성하고, Assistant 에게 메시지를 제출\n",
    "    thread= client.beta.threads.create()\n",
    "    run = submit_message(ASSISTANT_ID, thread, user_input)\n",
    "    return thread, run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동시에 여러 요청을 처리하기 위해 스래드를 생성합니다.\n",
    "thread1, run1 = create_thread_and_run('스타벅스 상표의 식별력은 어떤가요?')\n",
    "thread2, run2 = create_thread_and_run('어떤 기준이 가장 중요한가요?')\n",
    "thread3, run3 = create_thread_and_run('어떻게하면 식별력 있는 상표를 만들 수 있을까요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# 메시지 출력용 함수\n",
    "def print_message(response):\n",
    "    for res in response:\n",
    "        print(f'[{res.role.upper()}]\\n{res.content[0].text.value}\\n')\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "#반복문에서 대기하는 함수\n",
    "def wait_on_run(run, thread):\n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id = run.id\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return run\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 첫 번째 실행을 위해 대기\n",
    "run1 = wait_on_run(run1, thread1)\n",
    "print_message(get_response(thread1))\n",
    "\n",
    "# 두 번째 실행을 위해 대기\n",
    "run2 = wait_on_run(run2, thread2)\n",
    "print_message(get_response(thread2))\n",
    "\n",
    "# 세 번째 실행을 위해 대기\n",
    "run3 = wait_on_run(run3, thread3)\n",
    "# 세 번째 스레드를 마치면 감사 인사를 전하고 종료합니다 :)\n",
    "run4 = submit_message(ASSISTANT_ID, thread3, \"도와주셔서 감사합니다!\")\n",
    "run4 = wait_on_run(run4, thread3)\n",
    "print_message(get_response(thread3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
